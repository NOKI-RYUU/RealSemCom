import sys
import os
import random
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import argparse
import torch
import torch.optim as optim
import torch.nn as nn
from torch.utils.data import DataLoader
from tqdm import tqdm
from models.vit_encoder import ViTEncoder
from models.vit_transformer_tx import ViTTransformerTX
from models.vit_transformer_rx import ViTTransformerRX
from models.reconstruction_network import ReconstructionNetwork
from models.channel_model import ChannelModel
from data.dataset import ImageDataset
from utils import save_checkpoint, save_best_model, load_checkpoint
from logger import Logger

# **âœ… ç»Ÿä¸€è·¯å¾„ç®¡ç†**
parser = argparse.ArgumentParser(description="Train Semantic Communication System")
parser.add_argument("--data_path", type=str, default="data/coco_dataset_original/train2017", help="Path to training images")
parser.add_argument("--faiss_index", type=str, default="data/knowledge_bases_coco_crop_background/knowledge_base_threshold_0.3/faiss_index/knowledge_base.index", help="Path to FAISS index")
parser.add_argument("--faiss_vectors", type=str, default="data/knowledge_bases_coco_crop_background/encoded_features/image_features.npy", help="Path to FAISS feature vectors")
parser.add_argument("--epochs", type=int, default=10, help="Number of training epochs")
parser.add_argument("--batch_size", type=int, default=32, help="Batch size")
parser.add_argument("--learning_rate", type=float, default=0.001, help="Learning rate")
parser.add_argument("--checkpoint_dir", type=str, default="checkpoints/", help="Path to save checkpoints")
parser.add_argument("--max_checkpoints", type=int, default=5, help="Maximum number of checkpoints to keep")
parser.add_argument("--channel_type", type=str, choices=["AWGN", "Rayleigh", "Rician"], default="AWGN", help="Type of channel model")
parser.add_argument("--k_factor", type=float, default=5.0, help="K-factor for Rician fading")
args = parser.parse_args()

# **âœ… è®­ç»ƒå‚æ•°**
EPOCHS = args.epochs
BATCH_SIZE = args.batch_size
LEARNING_RATE = args.learning_rate
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
CHECKPOINT_DIR = args.checkpoint_dir
MAX_CHECKPOINTS = args.max_checkpoints
LATEST_CHECKPOINT = os.path.join(CHECKPOINT_DIR, "checkpoint_latest.pth")

# **âœ… åˆå§‹åŒ–æ¨¡å‹**
encoder = ViTEncoder().to(DEVICE)
tx_vit = ViTTransformerTX().to(DEVICE)
rx_vit = ViTTransformerRX().to(DEVICE)
decoder = ReconstructionNetwork().to(DEVICE)
channel = ChannelModel(channel_type=args.channel_type, k_factor=args.k_factor).to(DEVICE)

# **âœ… é¢„åŠ è½½ FAISS æ•°æ®ï¼Œæé«˜æŸ¥è¯¢æ•ˆç‡**
dataset = ImageDataset(args.data_path, args.faiss_index, args.faiss_vectors)
dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=32, pin_memory=True)

# **âœ… åˆå§‹åŒ–ä¼˜åŒ–å™¨**
optimizer = optim.Adam(
    list(tx_vit.parameters()) + list(rx_vit.parameters()) + list(decoder.parameters()),
    lr=LEARNING_RATE,
)
criterion = nn.MSELoss()

# **âœ… è®­ç»ƒæ—¥å¿—ï¼ˆTensorBoardï¼‰**
logger = Logger()

# **âœ… å°è¯•åŠ è½½ä¸Šæ¬¡è®­ç»ƒçš„ checkpoint**
if os.path.exists(LATEST_CHECKPOINT):
    tx_vit, optimizer = load_checkpoint(tx_vit, optimizer, LATEST_CHECKPOINT)
    rx_vit, optimizer = load_checkpoint(rx_vit, optimizer, LATEST_CHECKPOINT)
    decoder, optimizer = load_checkpoint(decoder, optimizer, LATEST_CHECKPOINT)
    print(f"âœ… æˆåŠŸåŠ è½½ {LATEST_CHECKPOINT}ï¼Œç»§ç»­è®­ç»ƒ...")

# **âœ… è®­ç»ƒå¾ªç¯**
best_loss = float("inf")

for epoch in range(EPOCHS):
    epoch_loss = 0

    # **æ¯ä¸ª epoch é€‰æ‹©ä¸€ä¸ªéšæœº SNR**
    snr = random.randint(0, 10)
    print(f"ğŸ“¡ Epoch {epoch+1}: ä½¿ç”¨ SNR={snr}")

    for batch_idx, (image, ref_feature) in enumerate(tqdm(dataloader, desc=f"Epoch {epoch+1}/{EPOCHS}")):
        # **ç¡®ä¿æ•°æ®ä¹Ÿåœ¨ GPU**
        image, ref_feature = image.to(DEVICE, non_blocking=True), ref_feature.to(DEVICE, non_blocking=True)

        # **é‡Šæ”¾ CUDA ç¼“å­˜ï¼Œé˜²æ­¢æ˜¾å­˜ç¢ç‰‡åŒ–**
        torch.cuda.empty_cache()

        # **ç¡®ä¿ GPU è®¡ç®—åŒæ­¥**
        torch.cuda.synchronize()

        # **å‘é€ç«¯**
        enc_feature = encoder(image)
        offset_feature = tx_vit(enc_feature, ref_feature)

        # **ä¿¡é“æ¨¡å‹ï¼ˆåŠ å…¥ SNRï¼‰**
        channel_feature = channel(offset_feature, snr)

        # **æ¥æ”¶ç«¯**
        recovered_feature = rx_vit(channel_feature, ref_feature)
        reconstructed_image = decoder(recovered_feature)

        # **ç¡®ä¿ GPU è®¡ç®—åŒæ­¥**
        torch.cuda.synchronize()

        # **è®¡ç®—æŸå¤±**
        loss = criterion(reconstructed_image, image)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        epoch_loss += loss.item()

        # **è®°å½•æ—¥å¿—**
        logger.log_scalar("Loss/Batch", loss.item(), epoch * len(dataloader) + batch_idx)

    # **è®°å½•æ¯è½®æŸå¤±**
    avg_epoch_loss = epoch_loss / len(dataloader)
    logger.log_scalar("Loss/Epoch", avg_epoch_loss, epoch)
    print(f"ğŸ“‰ Epoch {epoch+1} Loss: {avg_epoch_loss:.5f}")

    # **âœ… ä¿å­˜ Checkpoint**
    if epoch % 5 == 0:
        save_checkpoint(tx_vit, optimizer, epoch, avg_epoch_loss, CHECKPOINT_DIR, MAX_CHECKPOINTS)
        save_checkpoint(rx_vit, optimizer, epoch, avg_epoch_loss, CHECKPOINT_DIR, MAX_CHECKPOINTS)
        save_checkpoint(decoder, optimizer, epoch, avg_epoch_loss, CHECKPOINT_DIR, MAX_CHECKPOINTS)

    # **âœ… ä¿å­˜æœ€ä½³æ¨¡å‹**
    if avg_epoch_loss < best_loss:
        best_loss = avg_epoch_loss
        save_best_model(tx_vit, optimizer, epoch, best_loss, "best_model_tx.pth")
        save_best_model(rx_vit, optimizer, epoch, best_loss, "best_model_rx.pth")
        save_best_model(decoder, optimizer, epoch, best_loss, "best_model_decoder.pth")

# **âœ… å…³é—­æ—¥å¿—**
logger.close()
