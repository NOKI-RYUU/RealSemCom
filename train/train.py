import os
import torch
import torch.optim as optim
import torch.nn as nn
from torch.utils.data import DataLoader
from tqdm import tqdm
from models.vit_encoder import ViTEncoder
from models.vit_transformer_tx import ViTTransformerTX
from models.vit_transformer_rx import ViTTransformerRX
from models.reconstruction_network import ReconstructionNetwork
from models.channel_model import ChannelModel
from data.dataset import ImageDataset
from train.utils import save_checkpoint, save_best_model, load_checkpoint
from train.logger import Logger

# è®­ç»ƒå‚æ•°
EPOCHS = 100
BATCH_SIZE = 8
LEARNING_RATE = 0.001
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
MAX_CHECKPOINTS = 5  # åªä¿ç•™æœ€è¿‘ 5 ä¸ª checkpoint
CHECKPOINT_DIR = "checkpoints/"
BEST_MODEL_PATHS = {
    "tx_vit": "best_model_tx.pth",
    "rx_vit": "best_model_rx.pth",
    "decoder": "best_model_decoder.pth",
}
LATEST_CHECKPOINT = os.path.join(CHECKPOINT_DIR, "checkpoint_latest.pth")

# åˆå§‹åŒ–æ¨¡å‹
encoder = ViTEncoder().to(DEVICE)
tx_vit = ViTTransformerTX().to(DEVICE)
rx_vit = ViTTransformerRX().to(DEVICE)
decoder = ReconstructionNetwork().to(DEVICE)
channel = ChannelModel().to(DEVICE)

# åŠ è½½æ•°æ®
dataset = ImageDataset("data/images")
dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)

# åˆå§‹åŒ–ä¼˜åŒ–å™¨
optimizer = optim.Adam(
    list(tx_vit.parameters()) + list(rx_vit.parameters()) + list(decoder.parameters()),
    lr=LEARNING_RATE,
)
criterion = nn.MSELoss()

# è®­ç»ƒæ—¥å¿—ï¼ˆTensorBoardï¼‰
logger = Logger()

# æœ€ä½³æŸå¤±åˆå§‹åŒ–
best_loss = float("inf")

# å°è¯•åŠ è½½ä¸Šæ¬¡è®­ç»ƒçš„ checkpoint
if os.path.exists(LATEST_CHECKPOINT):
    tx_vit, optimizer = load_checkpoint(tx_vit, optimizer, LATEST_CHECKPOINT)
    rx_vit, optimizer = load_checkpoint(rx_vit, optimizer, LATEST_CHECKPOINT)
    decoder, optimizer = load_checkpoint(decoder, optimizer, LATEST_CHECKPOINT)
    print(f"âœ… æˆåŠŸåŠ è½½ {LATEST_CHECKPOINT}ï¼Œç»§ç»­è®­ç»ƒ...")

# è®­ç»ƒå¾ªç¯
for epoch in range(EPOCHS):
    epoch_loss = 0
    for batch_idx, (image, ref_feature) in enumerate(tqdm(dataloader, desc=f"Epoch {epoch+1}/{EPOCHS}")):
        image, ref_feature = image.to(DEVICE), ref_feature.to(DEVICE)

        # å‘é€ç«¯
        enc_feature = encoder(image)
        offset_feature = tx_vit(enc_feature, ref_feature)

        # ä¿¡é“æ¨¡å‹
        channel_feature = channel(offset_feature)

        # æ¥æ”¶ç«¯
        recovered_feature = rx_vit(channel_feature, ref_feature)
        reconstructed_image = decoder(recovered_feature)

        # è®¡ç®—æŸå¤±
        loss = criterion(reconstructed_image, image)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        epoch_loss += loss.item()

        # è®°å½•æ—¥å¿—
        logger.log_scalar("Loss/Batch", loss.item(), epoch * len(dataloader) + batch_idx)

    # è®°å½•æ¯è½®æŸå¤±
    avg_epoch_loss = epoch_loss / len(dataloader)
    logger.log_scalar("Loss/Epoch", avg_epoch_loss, epoch)
    print(f"ğŸ“‰ Epoch {epoch+1} Loss: {avg_epoch_loss:.5f}")

    # ä¿å­˜ checkpointï¼ˆæ¯ 5 è½®ä¿å­˜ä¸€æ¬¡ï¼‰
    if epoch % 5 == 0:
        save_checkpoint(tx_vit, optimizer, epoch, avg_epoch_loss, checkpoint_dir=CHECKPOINT_DIR, max_checkpoints=MAX_CHECKPOINTS)
        save_checkpoint(rx_vit, optimizer, epoch, avg_epoch_loss, checkpoint_dir=CHECKPOINT_DIR, max_checkpoints=MAX_CHECKPOINTS)
        save_checkpoint(decoder, optimizer, epoch, avg_epoch_loss, checkpoint_dir=CHECKPOINT_DIR, max_checkpoints=MAX_CHECKPOINTS)

        # ä¿å­˜æœ€æ–° checkpoint ä»¥æ”¯æŒæ–­ç‚¹ç»­è®­
        save_checkpoint(tx_vit, optimizer, epoch, avg_epoch_loss, checkpoint_dir=CHECKPOINT_DIR, max_checkpoints=1)

    # æ›´æ–°æœ€ä½³æ¨¡å‹
    if avg_epoch_loss < best_loss:
        best_loss = avg_epoch_loss
        save_best_model(tx_vit, optimizer, epoch, best_loss, best_model_path=BEST_MODEL_PATHS["tx_vit"])
        save_best_model(rx_vit, optimizer, epoch, best_loss, best_model_path=BEST_MODEL_PATHS["rx_vit"])
        save_best_model(decoder, optimizer, epoch, best_loss, best_model_path=BEST_MODEL_PATHS["decoder"])

# å…³é—­æ—¥å¿—
logger.close()
