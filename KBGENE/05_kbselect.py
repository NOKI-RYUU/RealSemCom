import os
import torch
import numpy as np
import faiss
import json
import shutil
from tqdm import tqdm
from datetime import datetime
from sklearn.metrics.pairwise import cosine_similarity


class KnowledgeBaseBuilder:
    def __init__(self, encoded_path, output_root, threshold=0.3):
        """
        åˆå§‹åŒ–çŸ¥è¯†åº“æ„å»ºç±»
        :param encoded_path: é¢„ç¼–ç ç‰¹å¾è·¯å¾„
        :param output_root: å­˜æ”¾çŸ¥è¯†åº“çš„æ ¹ç›®å½•
        :param threshold: è¯­ä¹‰ç›¸ä¼¼åº¦é˜ˆå€¼
        """
        self.encoded_path = encoded_path
        self.output_path = os.path.join(output_root, f"knowledge_base_threshold_{threshold}")
        self.image_output_path = os.path.join(self.output_path, "images")
        self.faiss_output_path = os.path.join(self.output_path, "faiss_index")
        os.makedirs(self.image_output_path, exist_ok=True)
        os.makedirs(self.faiss_output_path, exist_ok=True)

        self.threshold = threshold

        # è¯»å–å·²ç¼–ç çš„ç‰¹å¾
        self.features = np.load(os.path.join(self.encoded_path, "image_features.npy"))
        with open(os.path.join(self.encoded_path, "image_metadata.json"), "r") as f:
            self.metadata = json.load(f)

        # ç»„ç»‡ç±»åˆ«æ•°æ®
        self.category_data = {}
        for idx, data in enumerate(self.metadata):
            category = data["category"]
            if category not in self.category_data:
                self.category_data[category] = {"features": [], "images": []}
            self.category_data[category]["features"].append(self.features[idx])
            self.category_data[category]["images"].append(data["image_path"])

        self.log_file = os.path.join(self.output_path, "log.txt")
        with open(self.log_file, "w") as log:
            log.write(f"çŸ¥è¯†åº“æ„å»ºå¼€å§‹: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            log.write(f"è¯­ä¹‰ç›¸ä¼¼åº¦é˜ˆå€¼: {self.threshold}\n\n")

    def log(self, message):
        """æ‰“å°å¹¶è®°å½•æ—¥å¿—"""
        print(message)
        with open(self.log_file, "a") as log:
            log.write(message + "\n")

    def build(self):
        """æ„å»ºç±»åˆ«å†…ç­›é€‰çš„çŸ¥è¯†åº“"""
        self.log(f"å‘ç° {len(self.category_data)} ä¸ªç±»åˆ«ï¼Œå¼€å§‹ç­›é€‰...")

        category_index = {}  # å­˜å‚¨ç±»åˆ«æ˜ å°„

        for category, data in tqdm(self.category_data.items(), desc="ğŸ” å¤„ç†ç±»åˆ«", unit="category"):
            features = np.array(data["features"])  # è¯¥ç±»åˆ«æ‰€æœ‰ç‰¹å¾
            images = data["images"]  # è¯¥ç±»åˆ«æ‰€æœ‰å›¾ç‰‡è·¯å¾„

            selected_features = []
            selected_images = []

            for i, feature in enumerate(features):
                if selected_features:
                    similarities = cosine_similarity([feature], selected_features)
                    max_similarity = similarities.max()
                else:
                    max_similarity = 0  # ç¬¬ä¸€ä¸ªæ ·æœ¬ç›´æ¥åŠ å…¥

                if max_similarity < self.threshold:
                    selected_features.append(feature)
                    selected_images.append(images[i])

                    # å¤åˆ¶å›¾ç‰‡åˆ°æ–°çš„åˆ†ç±»æ–‡ä»¶å¤¹
                    category_output_path = os.path.join(self.image_output_path, category)
                    os.makedirs(category_output_path, exist_ok=True)
                    new_img_path = os.path.join(category_output_path, os.path.basename(images[i]))
                    shutil.copy(images[i], new_img_path)

            # æ„å»º FAISS ç´¢å¼•
            if selected_features:
                selected_features = np.array(selected_features)
                faiss_index = faiss.IndexFlatL2(selected_features.shape[1])
                faiss_index.add(selected_features)
                faiss.write_index(faiss_index, os.path.join(self.faiss_output_path, f"{category}.index"))

                # è®°å½•ç±»åˆ«ç´¢å¼•
                category_index[category] = selected_images

                self.log(f"{category} çŸ¥è¯†åº“æ„å»ºå®Œæˆï¼Œå…± {len(selected_features)} å¼ å›¾ç‰‡")

        # ä¿å­˜ç±»åˆ«ç´¢å¼•
        category_index_path = os.path.join(self.output_path, "category_index.json")
        with open(category_index_path, "w") as f:
            json.dump(category_index, f, indent=4)

        self.log(f"ç±»åˆ«ç´¢å¼•å·²ä¿å­˜è‡³: {category_index_path}")
        self.log(f"çŸ¥è¯†åº“æ„å»ºå®Œæˆï¼å…±å¤„ç† {len(self.category_data)} ä¸ªç±»åˆ«")


if __name__ == "__main__":
    builder = KnowledgeBaseBuilder("coco_dataset/knowledge_bases_coco_crop/encoded_features", "coco_dataset/knowledge_bases_coco_crop", threshold=0.3)
    builder.build()
