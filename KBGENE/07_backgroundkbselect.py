import os
import torch
import numpy as np
import faiss
import json
import shutil
from tqdm import tqdm
from datetime import datetime
from sklearn.metrics.pairwise import cosine_similarity


class KnowledgeBaseBuilder:
    def __init__(self, encoded_path, output_root, threshold=0.3):
        """
        åˆå§‹åŒ–çŸ¥è¯†åº“æ„å»ºç±»
        :param encoded_path: é¢„ç¼–ç ç‰¹å¾è·¯å¾„
        :param output_root: å­˜æ”¾çŸ¥è¯†åº“çš„æ ¹ç›®å½•
        :param threshold: è¯­ä¹‰ç›¸ä¼¼åº¦é˜ˆå€¼
        """
        self.encoded_path = encoded_path
        self.output_path = os.path.join(output_root, f"knowledge_base_threshold_{threshold}")
        self.image_output_path = os.path.join(self.output_path, "images")
        self.faiss_output_path = os.path.join(self.output_path, "faiss_index")
        os.makedirs(self.image_output_path, exist_ok=True)
        os.makedirs(self.faiss_output_path, exist_ok=True)

        self.threshold = threshold

        # è¯»å–å·²ç¼–ç çš„ç‰¹å¾
        self.features = np.load(os.path.join(self.encoded_path, "image_features.npy"))
        with open(os.path.join(self.encoded_path, "image_metadata.json"), "r") as f:
            self.metadata = json.load(f)

        self.log_file = os.path.join(self.output_path, "log.txt")
        with open(self.log_file, "w") as log:
            log.write(f"çŸ¥è¯†åº“æ„å»ºå¼€å§‹: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            log.write(f"è¯­ä¹‰ç›¸ä¼¼åº¦é˜ˆå€¼: {self.threshold}\n\n")

    def log(self, message):
        """æ‰“å°å¹¶è®°å½•æ—¥å¿—"""
        print(message)
        with open(self.log_file, "a") as log:
            log.write(message + "\n")

    def build(self):
        """æ„å»ºçŸ¥è¯†åº“ï¼Œç­›é€‰å…·æœ‰ä»£è¡¨æ€§çš„å›¾ç‰‡"""
        self.log(f"å‘ç° {len(self.features)} å¼ å›¾ç‰‡ï¼Œå¼€å§‹ç­›é€‰...")

        selected_features = []
        selected_images = []

        for i, feature in tqdm(enumerate(self.features), total=len(self.features), desc="ğŸ” ç­›é€‰å›¾ç‰‡", unit="img"):
            if selected_features:
                similarities = cosine_similarity([feature], selected_features)
                max_similarity = similarities.max()
            else:
                max_similarity = 0  # ç¬¬ä¸€å¼ å›¾ç‰‡ç›´æ¥åŠ å…¥

            if max_similarity < self.threshold:
                selected_features.append(feature)
                selected_images.append(self.metadata[i]["image_path"])

                # å¤åˆ¶å›¾ç‰‡åˆ°æ–°çŸ¥è¯†åº“
                new_img_path = os.path.join(self.image_output_path, os.path.basename(self.metadata[i]["image_path"]))
                shutil.copy(self.metadata[i]["image_path"], new_img_path)

        # æ„å»º FAISS ç´¢å¼•
        if selected_features:
            selected_features = np.array(selected_features)
            faiss_index = faiss.IndexFlatL2(selected_features.shape[1])
            faiss_index.add(selected_features)
            faiss.write_index(faiss_index, os.path.join(self.faiss_output_path, "knowledge_base.index"))

            # è®°å½•ç´¢å¼•
            index_data = {"selected_images": selected_images}
            with open(os.path.join(self.output_path, "image_index.json"), "w") as f:
                json.dump(index_data, f, indent=4)

            self.log(f"çŸ¥è¯†åº“æ„å»ºå®Œæˆï¼Œå…± {len(selected_features)} å¼ å›¾ç‰‡")

        else:
            self.log("æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„å›¾ç‰‡ï¼")


if __name__ == "__main__":
    builder = KnowledgeBaseBuilder(
        "coco_dataset/knowledge_bases_coco_crop_background/encoded_features",
        "coco_dataset/knowledge_bases_coco_crop_background",
        threshold=0.3
    )
    builder.build()
